<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[10分钟带你认识区块链]]></title>
    <url>%2F2018%2F06%2F07%2Fqukuailian%2F</url>
    <content type="text"><![CDATA[10分钟带你认识区块链刚接触区块链这个概念的时候, 相信很多人都会有跟我一样的疑问: 区块链倒底是什么? 拿来干什么用的? 怎么用? 它和比特币是什么关系? 你会带着一头的问号打开搜索引擎. 一般会得到如下的解答: 区块链会引发下一轮的技术革命 区块链是人类历史上在金融领域最大的突破, 区块链会引发社会和经济的重大变革. 有一些反对的意见, 认为区块链的价值被夸大了, 比特币是人类史上最大的泡沫 …. 还有更专业一些的回答: 区块链就是一个去中心化的分布式帐本. 区块链信息不可篡改. 区块链是比特币的底层协议. 类比于信息互联网的HTTP协议, 区块链就是”价值互联网”的”HTTP协议”. 区块链的最大价值在于它的智能合约系统 这很容易给人留下一个复杂, 高深又神秘的印像. 其实抛开用于解决具体问题的一系列复杂的场景. 区块链不过就是一个简单的数据结构. 我认为区块链的复杂不在于他的复杂场景的处理逻辑, 而是在于它的生态形成的内在逻辑. 这个逻辑是比特币之所以流行的原因. 也是众人讨论的焦点. 不过各位不用担心, 在你读完这篇文章的时候, 你一定也可以理解这一点, 我会带着你们由浅入深的进行探讨. 认识区块链区块链这个词源于中本聪的比特币白皮书&lt;比特币: 一种点对点的电子现金系统&gt;, 在文中其实并没有区块链这个词, 只有”区块”(Block)和”链”(Chain). 我们就从这两个词来入手. 其实区块链确实就是用”链”连接起来的”区块”而已. 也许你会说, 这未免也太简单了吧! 这么个结构, 怎么不可篡改的? 怎么存储帐本的? 怎么去中心化的? 怎么实现比特币的? … 更多的疑问向你袭来. 不要急, 让我们一个一个来分析. 怎样不可篡改?区块链是如何实现不可篡改的呢? 我们把上面的图复杂一下. 区块的连接方式是, 下一个新的区块总是指向上一区块的头部的Hash值. 而不可篡改的原因, 正是因为这种Hash指针的连接方式. 这个Hash值是根据区块内容以及一些其它参数经过Hash函数的计算生成的. Hash的原理有兴趣的同学可以自行查阅, 我们只需要知道它的几个主要特点: 对于不同的两个初始值, 只有极低到可以忽略不计的机率找到相同的Hash值. 对于不同的Hash值, 其对应的初始值一定不同. 不可逆, 无法通过Hash值倒推出初始值 这也就是说, 当一个区块有效生成的时候, 区块的内容是固定的, 其头部的Hash值也是固定的. 这样, 区块链在它最初始的区块(称为创世区块)到最新的区块的链条里面, 其内容都是不容修改的. 任何一个区块的修改, 都会引起链条的脱节. 了解了这一点, 你又会有问题了: 难倒区块链这么脆弱, 如果有黑客把区块的内容改了, 造成了区块链的断开, 那整个区块链会不会挂掉了? 这就涉及到我们要说的下一个问题了. 如何去中心化?前面也提到了, 区块链的一个特点就是去中心化的. 所谓去中心化是与中心化相反的概念. 我们平时使用的网页是中心化的, 因为它需要一个服务器来提供网页服务, 网页服务器挂掉了大家都看不了网页内容. 银行系统是中心化的, 因为它的数据由统一的服务器数据库来保存, 如果数据库挂掉了, 大家的钱就都不见了. 去中心化刚好相反, 没有一个统一的中心服务器来管理, 区块链的数据保存在网络中的每个区块链的节点上. 这也就解决了上一节提出的问题. 如果你的区块链被改动断开了, 对整个区块链是没有影响的, 因为还有其它节点没有断开. 在整个区块链网络中. 你的这个改动会被直接忽略了. 在网络中节点是这样一个概念. 一个网络中的节点存储区块链的所有信息. 这个节点有多大呢?比特币的单个区块, 最大是1M, 大约每10分钟生成一个. 其数据量一年也才增加50G左右. 因为比特币前些年的交易量较小, 一个区块远没有1M, 近两年才可能到达1M, 所以到现在区块总大小也才200G不到而已.PS: 其实比特币的区块大小限制, 以及生成规则限制, 直接决定了比特币能处理的上限为每秒约3.5个交易. 所以近些年比特币圈一直在讨论关于扩容的事. 每个节点都存储着整个区块链的所有信息, 这些节点称为全节点, 也叫挖矿节点(我们后面会介绍). 在整个网络, 存在众多这样的节点, 它们交织形成区块链的网络. 区块链中每个节点都能与其它的相邻几个节点相互通信连接. 节点间通信的一个最重要的内容就是商量出一个结论: 决定一个区块链应该包含哪些区块. 我们知道, 网络是不可信的, 存在延迟和同步等等问题, 一个一致的结论要如何达成呢? 这就涉及到了区块链的共识算法. 简单来说, 就是所有节点达成一个共识: 只要发现了其它节点的区块链上的链条比自己的链条长, 那就认为那条最长的是区块链, 本地不在这条最长链上的区块, 会被抛弃. 在上面提到的区块链被篡改的例子里, 之所以被改动的区块链会被忽略也是因为这个原因. 讲到这里时, 你可能会问: 如果有一个黑客, 把自己的区块链条改的很长, 会不会控制了整个区块链? 下面一节可以给以解答. 什么是挖矿?在现实世界中, 挖矿是为了赚取收益的, 在区块链中也是一样. 以比特币为例. 比特币的矿工每发现一个新区块, 现在可以赚取12.5个比特币的收益(这个收益每四年减半), 按现在市值大概11W美金, 这个收益还是相当可观的. 之所以用挖矿来比喻发现一个新区块, 是因为要找到一个新的区块并不简单. 从上文中知道, 区块之间是通过Hash值进行链接的. 但是这个Hash值一定要符合特定的规则才算是一个有效的区块. 我们把上面的区块继续细化, 假设矿工想要”挖”到一个有效的新区块, 他需要进行如下的计算: 有效区块需满足: H(A, B, C) &lt; 目标Hash值. 其中: H是Hash函数, 比特币使用sha-256算法. A是区块的内容的Hash值(需注意并不是当前区块的Hash值) B是一个32位的随机数. 矿工需要通过调整这个值, 来使上面的公式满足. C称为币基参数, 包含矿工的个人信息和随机数. 当经过2^32次运算后, 如果依然不能使条件满足, 就需要调整币基参数中的随机数, 继续进行遍历B的运算. 前面在介绍Hash函数时介绍过, Hash函数是不可逆的. 因此矿工只能通过不断的遍历随机数, 才可能得到目标Hash值的解. 在区块链网络中, 所有的矿工都在竞争去做这样的一道运算题, 期待自己可以先得到答案. 先解出答案的矿工会把生成的新区块连接到自己的区块链的末端, 然后向相邻的节点广播自己最新的区块状态. 相邻节点收到通知后, 会更新自己的区块状态, 然后继续广播出去. 接到通知的节点除了更新自己的区块状态以外, 还会中止自己在前一区块的挖矿运算, 在新的区块基础上开始新的挖矿运算. 很显然如果它还在原来的基础上挖矿, 即使得到了最终的解, 还是会因为落后其它节点一个区块的长度, 而被废弃. 在这里可以看出, 挖矿的难度非常大, 而且竞争非常激烈. 因此上一节中的问题基本不可能发生, 因为没有一个黑客有如此大的算力可以一直领先其它矿工找到新的区块. 在此还有三点需要说明: 每个节点计算的题目都是不同的. 因为大部分情况下区块的内容A都不相同. 即使A完全相同, C也会不同. 所以不存在同解的情况. 如果两个节点同时发现了新的区块. 相邻节点会根据通知的到达顺序, 来决定使用谁的区块. 在传播的过程中, 总有一个会被淘汰. 条件中目标Hash值不是固定的. 它会根据固定区块产生的频率来自动调整难度. 目标Hash值越小, 难度越大. 最终新区块产生的频率会维持在一个均值. (比特币是10分钟左右) 到这里, 我们已经介绍完了, 区块链的产生, 数据结构, 以及组织方式. 不过稍微有点知识的朋友, 可能会有一个关于区块链终极问题的考虑: 区块链的赖以生存的条件就是新区块的产生, 而新区块的产生有赖于挖矿节点对利益的需求, 如果有一天矿被”挖空”了怎么办? 区块链的终极问题矿被”挖空”的情况并不是危言耸听, 这一天总是会到来的. 以比特币为例, 比特币的总量为2100万, 到现在已经挖了1700万, 预计到2140年, 全部比特币会被挖空. 这一天的到来意味着, 新产生的区块不会再有比特币奖励. 还会有矿工愿意贡献自己的电量, 存储, 以及硬件设备, 来维持区块链的正常运转吗? 其实这一点我们可以不用担心. 矿工在挖矿中的收益除了来自于区块奖励, 还有一部分就是矿工将交易纳入区块中的手续费用. 这一部分的收益现在还比较低, 但是相信将来应该会成为矿工的主要收益来源. 总结我想你应该已经大概理解了. 区块链通过区块来存储数据, 使用Hash指针连接区块, 来保证区块链上内容不可篡改. 区块链网络中存在很多存储全量区块数据的节点, 节点间通过共识算法使用最长的区块作为区块链, 以此达到去中心化. 矿工通过挖矿赚取收益，由此保证新区块的产生. 区块链通过设置有难度的挖矿难题, 来保证区块链的健康运作. 认识比特币仅管理解了区块链的一些原理, 可能你还会有些迷惑: 比特币是如何在区块链上交易的? 它和我们平时使用的货币有什么区别? 在一个去中心化的网络中, 要怎么证明一个比特币是属于我的呢? … 不用急, 我们先从最基本的谈起. 谈谈比特币是什么? 比特币是什么?我们平时接触的是人民银行发行的流通货币, 称为法币. 拿着它可以跟商店老板一手交钱一手交货, 也可以存入微信, 支付宝刷二维码付款. 它的价值就体现在流通上. 比特币的作用也是类似. 你可以认为比特币就是一种流通的介质. 只不过比特币不同于法币, 无法拿出一个称为比特币的硬币来, 它的存在就是网络世界中的代码. 所以你看到图片中一个着B字的黄色硬币图案, 其实是不存的, 那都是为了表示抽象概念的形象表示而已. 比特币在区块链的代码中, 不是一个数据结构, 也不是一个对象. 其实就是一个交易的记录. 比特币只能在挖矿得到新区块的奖励中产生, 所以矿工挖到的新区块, 会带有一个初始交易(称为币基交易). 这个初始交易的输入为空, 输出为矿工的帐户和比特币的数量. 因此矿工的帐户增加了相应数额的比特币. 记得我们之前挖矿的一节提到过, 有时需要调整币基参数来遍历解题, 矿工的帐户信息就存在于这个币基参数之中. 那么, 在比特币中帐户是怎么来的呢? 什么是比特币的帐户?一提到帐户, 读者心中一定会联想起在银行大厅中开户的繁琐流程. 开户, 注册, 提交资料….这些流程无一不是和中心化的体系相联系的. 在一个去中心化的比特币系统中则要简单的多. 比特币帐户的核心是使用密码学中的数字签名方案: 用户使用数字签名算法(比特币使用ECDSA)生成一对公钥PK和私钥SK: PK, SK = 生成签名(随机数) 对于一段特定的信息message, 可以生成信息签名: sig = 签名函数(SK, message) 则可以得到一个验证: isvalid = 验证(PK, message, sig). 如果验证通过, 可以得到这样一个结论: 信息message是由PK和SK这一对组合发出的, 因为只有PK能验证通过. 换句话说信息message是属于PK和SK的, 签名就是证据 所以, 在比特币中就把公钥看做一个用户的帐户. 不过一般公钥比较长, 比特币就使用公钥的Hash值看做是用户的收款地址. 所以用户帐户为: 12PK, SK = 生成签名(随机数);用户帐户 = Hash(PK); 同时, 用户需要保存自己的私钥PK. 以便于交易时, 证明比特币由用户自身持有, 如: 123message = &quot;用户A持有2比特币&quot;;//message是资产的证明, 实际中代表区块链中一个真实的交易记录sig = 签名函数(SK, message);验证通过 = 验证(PK, message, sig) &amp;&amp; (Hash(PK)==用户A的帐户); 这里的逻辑稍有些复杂, 读者朋友需细细体会. 不太了解也可以先略过. 你只需要知道帐户就是用户定义的一个公钥(银行帐号), 用户需要保存自己的私钥(取钱密码)来使用帐上的钱. 好了. 你现在已经有了一个比特币帐户, 而且帐户上可能还有一些数量的比特币, 应该如何交易呢? 用户如何交易?在刚一开始了解比特币交易时, 我有一个误解. 误以为比特币的交易类似于淘宝, 京东的交易清单, 需要金钱与实物的关联. 可想而知那个数据量需要多么的庞大. 但其实比特币的交易就像是我们银行帐户的里面的转入和转出, 只有转帐地址与转帐数额(交易时间等必要信息)的记录, 其数据量是相当小的. 至于交易的原因, 则由交易双方线下完成. 说到交易就是提到一系列的安全问题: 首先你要证明你拥用这笔钱. (对应: 银行帐户的余额) 保证收款人收到了这笔钱. (对应: 收款人收到钱) 保证你没有把这笔钱重复转给了两个人. (对应: 已经转给了帐户A, 就无法再转给帐户B) 比特币在交易的设计用一种巧妙的方式解决了这些问题, 我们来一一解答: 归属问题在前面介绍比特币来源时, 我们提到了币基交易, 这是由新区块奖励产生的只有输出, 没有输入的一个交易. 币基交易是一类特殊的交易, 用户之间的交易是必须同时存在输入和输出的. 而交易的输入就是之前已存在的交易的输出. 可以这样说: 帐户持有的比特币, 就是帐户对应的交易输出. (这些输出没有作为输入进行交易过). 如下图: 图中交易流程表示:帐户A通过币基交易得到12.5个币, 然后交易给帐户B 5个币, 又交易给帐户C 3个币. 我们可以看到, 在对于帐户A一系列的交易记录中, 只有交易3的第二个输出没有作为输入交易过, 所以帐户A的余额就是4.5个币. 你也许会说, 一个帐户可能对应的交易有很多啊. B也可以转给A几个币, C也可以转给A几个币, 这个怎么统计? 如果A想要花一笔大价钱买东西怎么办? A可以把多个交易向自己的输出作为输入, 去向其它帐户交易. A也可以为了方便, 通过这种方式, 把多个零散的交易输出作为输入, 指定自己为输出, 完成以零换整的过程. 另外, 交易的输入和输出不一定是相等的. 用户可以选择输出小于输入, 将这一部分差额作为交易的费用支付给矿工. 因为矿工是负责的记帐的人. 记帐过程要确保一项交易的完成, 就需要记帐. 记下帐来就既能确定收帐人拿到了币, 又能保证交款人不能抵赖, 拿同样的钱再去进行别的交易. 比特币是如何记帐的呢? 比特币记帐就是把我们上面提到的交易记录, 存储到区块上. 之前我们提到过生成的区块已经不能修改, 所以新的交易都是记录在新的区块上, 这依赖于矿工的工作. 回到我们之前的挖矿工作上来: 矿工在挖矿的时候, 会选择一些交易纳入到区块内容中. 以图中的组织形式(称为梅克尔树)进行编译, 所以得到了挖矿运算需要用到的一个参数 Hash值A. 根据Hash的特性, 对于Hash值A, 就是代表了整个树的信息. 对树上任何交易的修改都会引起Hash值的变化. 刚刚提到矿工会选择交易, 有必要说明一下: 每个挖矿节点都会存在一个交易池, 交易池可以监听到区块网络中传递过来的交易信息. 矿工是可以挑选哪些交易进入区块的, 比如交易费比较高的交易. 最终如果生成了有效的区块, 矿工就可以得到相应的交易的差额. 是不是新成了包含相应交易的有效区块, 就算交易成功了呢? 不一定哦! 我们之前说过, 新成了有效区块, 并不代表新区块会被纳入区块链, 还有可能被丢弃. 只有在得到区块链中其它节点的共识后, 才算真正的记帐成功. 所以比特币中存在一个交易确认的过程. 一般认为经过6次确认就算交易成功了, 即当前区块链后又生成了6个新的区块. 所以要确定你的交易已经成功, 需要经过大概1个小时. (前面讲过, 新区块生成间隔为大概10分钟) 如果你能够耐心看下来, 流程应该已经了解得差不多了. 想要试着去交易一下了. 但是一个难题摆在面前, 200G的区块链全量数据还是有点太大了, 你又不想去挖矿, 要怎么才能交易呢? 轻量节点:SPV其实在比特币系统里, 大部分都是跟你一样的用户, 只关心与自己相关的一小部分交易. 这部分用户就是做为比特币网络中的轻量节点. 这类节点不存储整个比特币区块链, 不会决定区块是否加入区块链, 不挖矿, 只存储和核验与自己相关的一小部分信息. 这类用户使用简单付款验证(SPV)客户端进行交易. 只需要几十M的数据. 讲到这里关于比特币你已了解得差不多了. 原理讲清了, 但好像还缺点什么? 最后你要知道的智能合约智能合约是区块链交易的一个中间环节, 我们知道在比特币交易时, 需要一个输入和输出, 在上面我们举的例子里, 输出只是一个帐户的地址和金额, 在智能合约交易中可以使用脚本地址作为输出地址. 类似于这样: 1OP_DUP OP_HASH160 be10f0a78f5ac63e8746f7f2e62a5663eed05788 OP_EQUALVERIFY OP_CHECKSIG 在交易被纳入区块链时, 相应的脚本指令会执行. 可以实现如: 第三方支付, 网络众筹, 博彩, 抵押担保, 保险等场景. 因为区块链去中心化以及不可篡改的安全性, 消除了机购存在欺诈的可能性, 提高了效率, 也消除了信任成本, 所以意义非常重大. 其它数字货币现在基于区块链的数字货币层出不穷, 大部分币种都是根据比特币衍生出来的. 它们的区别, 在于对比特币一些规则的改动和优化. 如: 调整挖矿算法, 调整区块大小, 调整共识规则, 调整区块生成时间等等. 最典型的是以太币, 它优化了智能合约, 创建了一个图灵完备的脚本系统, 大大拓展了智能合约的使用场景. 我的看法区块链技术不是什么新兴的技术, 只是原有技术的优化组合. 但它构成了一个自驱动, 自发展, 安全自治的生态系统, 为现有的价值体系提供了新的思路. 相信一定会有更好的发展. 不过当今概念炒作盛行, 很多人在还没有理解的情况下, 看到有利可图就一窝蜂涌入实在不可取. 希望有更多的人能理解区块链, 用好区块链, 发展区块链, 而不是炒作区块链.]]></content>
      <categories>
        <category>技术研究</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[跨进程通信工具Messenger]]></title>
    <url>%2F2017%2F09%2F14%2FMessenger%2F</url>
    <content type="text"><![CDATA[跨进程通信工具Messenger版本更新见 历史版本 工具说明MMessenger是一个跨进程通信工具， 与系统提供的Messenger不同。 MM可以拓展了功能， 支持同步， 异步， 注册操作等等。彻底封装实现逻辑， 为使用者提供了方便了拓展和便利的接口使用。 使用方法123dependencies &#123; compile &quot;com.mapeiyu.messenger:messenger:1.0.0&quot;&#125; 工具分为两部分， Server端功能支持与Client端功能支持。下面我们分两步来讲解。 Server端Server端是用来提供服务为外部使用的， 我们提供了便利的接口来方便Server端的功能拓展。 在Application中添加处理器BaseSVHandler, 其中定义handlerName方便三方找到此方法. 1234567891011121314151617181920212223242526272829303132MServer.addHandler(&quot;Plus&quot;, new BaseSVHandler() &#123; @Override public Bundle onRequestSync(Bundle request, ICallback callback) &#123; int a = request.getInt(&quot;A&quot;); int b = request.getInt(&quot;B&quot;); Bundle result = new Bundle(); result.putInt(&quot;RESULT&quot;, a + b); return result; &#125; @Override public void onRequestAsync(final Bundle request, final @NonNull ICallback callback) &#123; //模拟耗时操作 try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; int a = request.getInt(&quot;A&quot;); int b = request.getInt(&quot;B&quot;); Bundle result = new Bundle(); result.putInt(&quot;RESULT&quot;, a + b); try &#123; callback.postResult(result); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; &#125;&#125;); 其中 onRequestSync为同步接口， 可以使Client端直接获得返回结果。onRequestAsync为异步接口， 在异步线程中执行，操作结果通过回调的形式返回 这样设置后， 接入方就拥有了， 提供给外部Client使用的能力。 Client端Client是服务的使用方， 在使用服务时， 有下面几个步骤。 连接服务 异步操作方式， 可用在所有场景MClient.connect(context: Context, target: String, connectCallback: IConnectCallback) 其中target为目标server的包名. 请求结果 请求结果也存在同步，异步两种方式， 与上面Server端的两种实现相对应.一个完整的Client端实现是这样的。注意Client端与Server端一定是对应的。 123456789101112131415161718192021222324252627MClient.connect(this, &quot;com.meizu.launcher&quot;, new ConnectCallback() &#123; @Override public void onConnected(@NonNull MBridge bridge) &#123; Bundle request = new Bundle(); request.putInt(&quot;A&quot;, 1); request.putInt(&quot;B&quot;, 2); try &#123; //同步请求的例子 Bundle result = bridge.requestSync(&quot;Plus&quot;, request); Log.e(&quot;result&quot;, result.getString(&quot;RESULT&quot;) + &quot;=&quot;); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; try &#123; //异步请求的例子 bridge.requestAsync(&quot;Plus&quot;, request, new ResultCallback() &#123; @Override public void onResult(Bundle result) throws RemoteException &#123; Log.e(&quot;result&quot;, result.getString(&quot;RESULT&quot;) + &quot;=&quot;); &#125; &#125;); &#125; catch (RemoteException e) &#123; e.printStackTrace(); &#125; &#125;&#125;);]]></content>
      <categories>
        <category>原创组件</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移动端网络优化方向]]></title>
    <url>%2F2017%2F08%2F17%2Fnetwork-opt%2F</url>
    <content type="text"><![CDATA[一个网络请求可以简单分为连接服务器 -&gt; 获取数据两个部分。 一. 连接服务器优化 不用域名，用 IP 直连（gslb）省去首次域名解析一般需要几百毫秒， 预防域名劫持带来的风险 服务器部署动态 IP选择最优的服务器IP进行连接， 服务器端还可以调优服务器的 TCP 拥塞窗口大小、重传超时时间(RTO)、最大传输单元(MTU) 二. 获取数据优化 连接复用(三次握手方面)节省连接建立时间，如开启 keep-alive 合并请求 减小请求数据大小post请求的body用gzip压缩， 请求头压缩， CDN缓存 减小返回数据大小api数据gzip压缩， 数据格式json, protobuf, 多个图片分变率， webp格式， 增量更新， 断点续传 三. 其它优化 预加载 延迟加载 并发请求]]></content>
      <categories>
        <category>优化</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本概念]]></title>
    <url>%2F2017%2F08%2F15%2FBasic-concept-of-database%2F</url>
    <content type="text"><![CDATA[数据库基础术语 数据库（DB）：长期存储在计算机内、有组织的、统一管理的相关数据的集合。 数据库管理系统（DBMS）：位于用户和操作系统之间的一层数据管理软件。 数据库系统（DBS）：实现有组织地、动态地存储大量关联数据、方便多用户访问的计算机硬件、软件和数据资源组成的系统 分类 关系数据库. 分布式数据库. 通常使用位于不同的地点的较小的计算机系统，通过网络连接构成完整的、全局的大型数据库。每台计算机有DBMS的一份完整拷贝，且具有自己局部的数据库。 对象数据库. 是用以对象形式表示信息的数据库。对象数据库的管理系统称为ODBMS或OODBMS。 网络数据库. 由数据和资源共享这两种方式结合在一起而成，也称Web数据库。它以后台（远程）数据库为基础，加上一定的前台（本地计算机）程序，通过浏览器完成数据的存储、查询等操作 体系结构 概念模式. 简称为模式，它表示了对数据的全局逻辑级的抽象级别，是数据库中全部数据的整体逻辑结构的描述。它由若干个概念记录类型组成，还包含记录间联系、数据的完整性、安全性等要求。在实现中，它可以对应于所有的表格。 内模式. 也称存储模式，表示了对数据的物理级的抽象级别。它是数据库中全体数据的内部表示或底层描述，是数据库最低一级的逻辑描述，它描述了数据在存储介质上的存储方式和物理结构，对应着实际存储在外存储介质上的数据库。它包括记录类型、索引、文件的组织等，用内模式描述语言来描述、定义。 外模式也称子模式，表示了对数据的局部逻辑级的抽象级别。它对应于用户级，是用户与数据库系统的接口，是用户用到的那部分数据的描述。在实现中可以对应于视图。 数据模型概念数据模型-ER模型 实体：客观存在，可以互相区别的事物。 属性：实体的特性 联系：实体之间的相互联系 逻辑数据模型 层次模型：用树形结构表示实体类型及实体间联系的数据模型，盛行于20世纪70年代。缺点是只能表示1:N的关系，且查询和操作很复杂。 网状模型：用有向图表示实体类型及实体间联系的数据模型，盛行于70年代至80年代中期。它的特点是记录之间联系通过指针实现，M:N也容易实现，查询效率较高。缺点是数据结构复杂，编程复杂。 关系模型：用二维表格表示实体集；用关键码而不是用指针导航数据。SQL语言是具有代表性的语言 物理数据模型关系数据库完整性规则 实体完整性规则，即主键的值不能是空值； 参照完整性规则，即不允许（通过外键）引用不存在的实体； 用户定义的完整性规则，比如属性“性别”只能接受“男”和“女”作为合法值，其它的输入都是非法的 运算 五个基本操作：并（Union，∪）、差（set difference，−）、笛卡儿积（Cartesian product，×）、投影（Projection，Π）和选择（Selection，σ）； 四个组合操作：交（Intersection，∩）、θ连接（θ-Join，θ）、自然连接（Natural join，⋈）和除法（Division，÷）； 七个扩充操作：改名（Rename，ρ）、广义投影、赋值（←）、外连接（Outer joins，⟕⟖⟗）、外部并、半连接（Semijoin，⋉ ⋊）、聚集操作（Aggregation）。 规范化理论 一范式. 无重复的列 二范式. 属性完全依赖于主键 三范式. 属性不依赖于其它非主属性 四范式. 禁止主键列和非主键列一对多关系不受约束 事务事务的基本属性 原子性（Atomicity）：一个事务对数据库的所有操作，是一个不可分割的工作单元。这些操作要么全部执行，要么什么也不做。 一致性（Consistency）：一个事务独立执行的结果，应保持数据库的一致性，即数据不会因事务的执行而遭到破坏。 隔离性（Isolation）：在多个事务并发执行时，系统应保证与这些事务先后独立执行的结果一样。 持久性（Durability）：一个事务一旦完成全部操作后，他对数据库的所有更新应永久地反映在数据库中 这些属性的首字母缩写为ACID。其中原子性是最主要的根本目标；其它三个是辅助的属性。 索引机制索引用来提高数据查找的效率，用户看不到索引的存在。注意：使用索引会使更新表的速度变慢，因为数据更新的同时还要更新索引。 优点第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。第四，在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能 缺点第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度 什么情况下用 经常搜索 主键， 外键 需要排序或限定范围的列 什么情况下不用 查询少， 数据少 数据量大的列(text, img, bit) 修改性能&gt;&gt;检索性能 分类 唯一索引。 限定列不重复 主键索引。 主键会自动创建 聚集索引。 一个表只能有一个。 物理顺序与逻辑顺序相同。 数据结构 B树 B+树 红黑树（索引不用） 视图机制视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易 用来对无权用户屏蔽数据。数据安全，逻辑数据独立性和操作简便性。 http://blog.csdn.net/kennyrose/article/details/7532032/http://www.cnblogs.com/anding/p/3254674.htmlhttp://blog.csdn.net/u011404663/article/details/45252899http://blog.csdn.net/hectorhua/article/details/13767361/]]></content>
      <categories>
        <category>基础复习</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[proguard点滴]]></title>
    <url>%2F2017%2F06%2F06%2Fprogard-in-aar%2F</url>
    <content type="text"><![CDATA[关于混淆proguard不止能混淆, 还会做代码裁剪, 方法内联等等优化, 一般在Android工程里, 我们用的最多的是裁剪(shrink), 优化(optimize)和混淆(obfuscate), 其中代码裁剪, 特别是对方法的裁剪, 是降低dex方法数的一条捷径. 在日常使用中, 我们把proguard的裁剪, 优化, 混淆等一系列步骤笼统的称为混淆 shrink裁剪. 会将一些无效代码给移除，即没有被显式调用的代码 optimize优化. 基于控制流、数据流分析后，删除、合并一些代码. 如给类加final, 内联方法， 合并方法等。。 obfuscate混淆. 混淆类名、属性名、方法名、变量名等，变成无意义的类似a,b,c,d…的名字 第三方SDK的混淆: SDK必须keep的部分, 如使用了反射等技术时需要做对应的keep 对公开API的keep, 这部分如果不keep, SDK接入方根本没法用. 但是SDK接入方并不可能使用到SDK里所有的公开API 科学做法提取共性activity类名必须keep -keep public class * extends android.app.Activity JNI方法必须keep -keepclasseswithmembers,includedescriptorclasses class * { native &lt;methods&gt;; } 其中 includedescriptorclasses, 加上它就能保证方法参数的类型不被混淆 keep住所有会在xml中使用的控件 -keepclasseswithmembers class * { public &lt;init&gt;(android.content.Context, android.util.AttributeSet); } 使用注解定义注解 @Retention(RetentionPolicy.CLASS) @Target({ElementType.TYPE, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.METHOD, ElementType.FIELD}) public @interface Keep { } proguard文件中定义规则 -keep,allowobfuscation @interface com.shaw.Keep -keep @com.shaw.Keep class * { *; } -keepclasseswithmembers class * { @com.shaw.Keep &lt;fields&gt;; } -keepclasseswithmembers class * { @com.shaw.Keep &lt;init&gt;(...); } -keepclasseswithmembers class * { @com.shaw.Keep &lt;methods&gt;; } 使用aarconsumerProguardFiles 是aar的接入方在构建时会使用的混淆规则proguardFiles 是用于构建aar的混淆规则 注：consumerProguardFiles这个属性只能在com.android.library即aar工程中使用。 这个很好理解。 但是consumerProguardFiles的规则是合并到调用方的proguard中一起在编译中生效的。 所以如果一个aar包中使用了 -keep class com.** { *; } 那SDK接入方com包下的一切都没法混淆了. 附proguard时机 参考 http://blog.csdn.net/jjwwmlp456/article/details/44977721 http://www.jianshu.com/p/14af4a474d55 https://www.guardsquare.com/en/proguard/manual/usage 联系 访问我的个人博客 马培羽 邮件 mason.mpy@gmail.com]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>proguard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过注解添加逻辑]]></title>
    <url>%2F2017%2F03%2F22%2Fadd-logic-through-annotation%2F</url>
    <content type="text"><![CDATA[做什么？？近期在为公司的项目做埋点。 因为之前做过几次， 深知这个东西的麻烦， 要频繁的往代码中添加重复逻辑。什么onStart, onStop全部都重写一遍， 做为一个码农，咱怎么也算是脑力劳动者， 什么时候变成干体力活了。研究了两天，绕了一个大弯， 终于找到了方法。记录一下这个过程。 注解处理器第一感觉是不是这个东西要用到编译时注解， 因为咱的目的是在编译时添加逻辑嘛。哼哧，哼哧。。。。 http://www.open-open.com/lib/view/open1470735314518.html 构造代码添加逻辑就是要自己构造代码喽。一般都是用方块的javapoet. 继续哼哧，哼哧。。。。 http://www.jianshu.com/p/95f12f72f69a https://github.com/square/javapoet 修改文件?哦。不对javapoet只能用来生成新的java文件。 不能用来修改class文件， 我们的目的是要修改生成的class文件啊。 nuwa怎么做到的记得之前热更新插件中可以修改class文件的， nuwa就是通过修改class文件来达到使类具有热修复能力的。 继续哼哧，哼哧。。。。 https://github.com/jasonross/Nuwa asm字节码原来用的asm字节码工具啊。 继续哼哧， 哼哧。。。。 https://www.ibm.com/developerworks/cn/java/j-lo-asm30/ http://asm.ow2.org/ 此路不通发现问题了啊。注解处理器无法处理修改类。同时注解处理器的处理时机是在编译之前， 即这里还没有生成class文件。 完蛋， 此路不通啊。。。。 gradle的task即然注解处理器的处理时机不对，不如我们自己来控制处理时机喽。在gradle的编译task上下文章。在java的compileJava task后面， 或者在 android的compileXXXSources task后面执行 asm的字节码处理。 看下面两个图: 效率问题但是这个效率太低了啊。 不像注解处理器一样， asm无法专门找到和处理某个annotation. 难倒要让asm扫描所有的类文件， 找到指定的annotation?? 注解处理器与gradle相结合只能想方法喽。 把注解处理器和gradle编译结合起来。先通过注解处理器把包含注解的类过滤出来， 然后在gradle的编译task后使用asm处理过滤出来的类。 找找别的办法貌似逻辑上可以走通哦，但总是感觉有那么一点点别扭。找找有没有别的办法。国内毛都查不到， 还是老外见多识广。 http://stackoverflow.com/questions/4851429/modify-a-method-using-annotations 大牛回复他跟我要实现的效果差不多。初始想法好像也是跟我差不多， 想用annotation processor来处理。 但是被第一个回复的大牛能否决了啊。 大牛还摘了一段wiki的原话， 意思是不能修改原annotation标注的类云云。但是我找了一下， 可能是版本升级吧。 大牛最关键的but annotation processors cannot modify the annotated code itself. 一句， 已被wike改成了and also modify the annotated code itself。 好像还是可以改， 所以回到第6步， 看来还是能用 annotation processor. 但在编译前的注解处理器，估计只能改java原文件吧。 class还没有编译出来啊。这不是我想要的。 hugo怎么做的再想想办法. 记得之前用过大神jake walton的log神器hugo. 可以通过一注解来打印函数的变量， 执行时间等等。 显然这只能是通过注解把逻辑注入到了函数中实现的。 https://github.com/JakeWharton/hugo AspectJ对于实现原理， 只能拿来了。 果然他用了另一种切面语言 AspectJ注入的逻辑。最初上面的老外那个问题， 大牛也提出了使用AspectJ Development Tools的解决方案。同时还不依不饶的让楼主使用。 我最初没在意， 以为就是一个eclipse的源码处理插件。通过ide的编译器做到的识别annotation插件代码， 类似搜索替换. 但通过hugo的使用， 看来是通用的。 http://blog.csdn.net/xxxzhi/article/details/53048476 http://blog.csdn.net/hp910315/article/details/52701809 方案确定在此， 确定了方案为使用 aspectJ来实现通过注解添加逻辑。一切参照hugo的代码实现即可。 我的简易实现代码. https://github.com/masonTool/AspectJDemo AspectJ粗浅的理解对于AspectJ， 这里记录一个粗浅的理解。 AspectJ可以理解为java的拓展。因为他是兼容java的。 AspectJ编译时使用自己的编译器ajc 是一种面向切面的语言。 切面与模块是相对应的。如果把面向对象形容为纵向， 则切面可以理解为横向。特别适合做log, 权限管理，埋点， 等等。将逻辑切入对象，同时又不破坏对象的逻辑独立性和耦合性。 一个最关键的概念就是Join Points. 翻译为”切入点”. 在Java中他定义了很多切入点，比如函数调用前， 函数执行前，函数执行后， 变量get时， 变量set时。。。总之发挥你的想象，基本上你想切入的点他都定义了。 怎么做到切入某个点呢？很自然， 首先筛选出想要切入的点(pointcut)， 然后处理筛选出来的点的逻辑(advice). 就是这样了。然后使用ajc去编译就可以了。 注意：如果你想在jar包中或者aar中使用aspectJ,不只需要使用ajc去编译生成包， 同时引用者也要使用ajc去编译才行。 如果不想啃官方文档 https://eclipse.org/aspectj/docs.php这篇文章可以带你入门 http://blog.csdn.net/innost/article/details/49387395 一点改进要想使用AspectJ不只需要引用org.aspectj:aspectjrt:1.8.6就完事了, 这个包只是让你编写代码用的，还需要自己处理编译逻辑。个人认为这个地方可以做得更简易一些， 就像groovy插件的自动编译一样。 所以我这里写了一个简易的gradle插件，copy到你的工程apply一下，就可以任性的编写aspectj代码，同时你也不用理会编译的事情了。https://github.com/masonTool/AspectJDemo/blob/master/aspect_compile.gradle 你可以直接使用，或者只做很小的改动来使用.当然这还只一个demo版本，但如果你是像我一样的新手，同时又不需要过多的高级配置的话，这已经足够好了.有时间我会把他以gradleplugin的形式发布到jcenter，让新手可以更方便的使用。]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>android</tag>
        <tag>annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android自动化测试入门篇]]></title>
    <url>%2F2017%2F03%2F02%2Fstart-android-test%2F</url>
    <content type="text"><![CDATA[Android的测试是基于JUnit的。 你可以基于JVM进行本地的单元测试(Local unit tests)， 也可以基于Android设备进行设备化的测试(instrumented tests)。 本文对构建Android测试的概念和工具， 进行一些简要的介绍. 测试类型对于你的项目中的任何一个模块，Android Studio提供了两个测试代码的目录。 你的测试代码必须写在这两个目录之中。这个两个目录就对应了相应的两个测试方法。 本地单元测试(Local unit tests) 目录位于 module-name/src/test/java/. 这些测试代码运行于本地JVM, 并且不会调用任何的Android框架的API. 如果你想了解详情， 请参阅构建本地单元测试 设备化测试(instrumented tests) 目录位于 module-name/src/androidTest/java/. 这些测试代码必须运行在Android硬件设备或者虚拟机上。 设备化测试在测试app时， 会同时构建一个测试APK运行在设备上。系统会把测试APK与app运行在同一个进程下， 所以测试代码中可以调用app的方法, 修改app的变量, 并且自动执行你的app的各种交互. 相要了解如何创建设备化测试， 请关注下面的主题： 构建设备化单元测试 : 构建存在Android系统依赖的复杂单元测试案例（在模拟对象无法满足的情况下）。 自动化界面测试: 构建测试案例验证用户界面行为的正确性（单应用的交互或者跨多应用的交互）。 测试App组件: 验证组件的行为， 比如 Service 或 Content Provider等用户不能直接交互的组件。 然而, 本地单元测试和设备化测试仅仅是术语, 用来帮助区分是在本地JVM上运行还是在Android平台上运行的(硬件设备或模拟器)。在构建一个完整的测试案例时，你应该通过下面表中的描述来理解真正的测试类型。 类型 子类型 描述 单元测试(Unit tests) 本地单元测试(Local Unit Tests) 运行于本地虚拟机(JVM)的单元测试. 当你的测试有没有Android框架依赖或者这些依赖可以模拟时， 使用这种测试可以使执行时间最少化. 设备化单元测试(Instrumented unit tests) 运行于Android设备或虚拟机的单元测试. 这种类型的测试可以获得Instrumentation信息， 比如你正在测试的app的上下文信息 Context. 当你的测试有不能被模拟的Android框架依赖时，使用这种测试。 集成测试(Integration Tests) 应用内组件测试(Components within your app only) 在交互中当用户执行一个特定的行为，或者键入一个特定的输入， 这种类型的测试可以验证目录app的行为是否符合预期。比如说， 当用户在应用的Activity界面中进行交互时，它可以让你检查目标app的界面响应是否正确。像Espresso这种UI测试框架, 可以让你用编程的方式去模拟用户的行为，和检测应用内部复杂的交互逻辑. 跨应用组件测试(Cross-app Components) 这种类型的测试， 可以验证不同的用户app间，用户app与系统app间的交互行为的正确性。比如说， 你可以验证当用户点击Android系统设置按钮时，你的app的行为是否正确。支持跨应用的交互框架，比如UI Automator允许你在这种场景下创建测试。 测试的API以下为测试Android应用常用的api JUnit你可以像写 JUnit4测试类一样写你的单元测试和集成测试。JUnit框架提供了一种便捷的方式在你的测试中进行安装， 卸载， 和断言操作。 一个基本的Junit4测试类是一个拥用一个或者多个测试方法的Java类。一个测试方法由@Test注解开始， 并且包含一段可以运行和验证单一功能的代码。 下面的代码片段展示了一个JUnit 4集成测试的例子， 例子中使用Espresso APIs 在一个UI元素上执行点击操作， 然后检查是否有一个预期的字符串展示。 123456789101112131415@RunWith(AndroidJUnit4.class)@LargeTestpublic class MainActivityInstrumentationTest &#123; @Rule public ActivityTestRule mActivityRule = new ActivityTestRule&lt;&gt;( MainActivity.class); @Test public void sayHello()&#123; onView(withText(&quot;Say hello!&quot;)).perform(click()); onView(withId(R.id.textView)).check(matches(withText(&quot;Hello, World!&quot;))); &#125;&#125; 在你的JUnit4测试类中， 你可以在你的测试代码中使用下面的注解调用特定处理的一部分。 @Before: 使用这个注解可以指定一段包含测试设置操作的代码。测试类在每个测试执行前调用这段代码。你可以定义多个带有@Before注解的方法， 但是在测试类中这个方法执行的顺序是不确的。 @After: 这个注解指定一段代码包含测试卸载操作。在每个测试方法执行后调用这段代码。你可以定义多个@After操作的代码。使用这个注解来释放内存中的资源。 @Test: 使用这个注解标识一个测试方法。 一个单独的测试类可以有多个测试方法 @Rule: @Rule通过复用的方法，可以允许你可以灵活的添加和修改每个测试方法。 在Android测试中， 此注解需要和Android测试支持库中提供的测试规则类配合命用。比如 ActivityTestRule和 ServiceTestRule @BeforeClass: 使用此注解来指定一个测试类的静态方法只能调用一次。这种测试步骤对于耗时操作非常有用， 例如连接数据库操作。 @AfterClass: 使用这个注解来指定一个静态方法， 当类中所有的测试方法都已经运行完成的时候调用。 这个步骤对释放@BeforeClass块中占用的资源非常有用。 @Test(timeout=): 一些注解支持在注解中设置变量值。 例如， 你可以指定一个测试的超时时间，如果一个测试开始并且没有在指定的超时时间内完成， 它自动认为校验失败。超时时间的单位是毫秒， 如 @Test(timeout=5000) 想了解更多注解， 可以参阅文档 JUnit annotations 和 Android annotations. 使用JUnit的Assert类来验证一个对象状态的正确性。asset方法比较你的期望值与真实值， 并且当两个值不相符时抛出一个异常。 Assertion classes对这些方法有详细的描述。 Android的测试支持库Android的测试支持库提供了一些API的集合， 使你可以快速的创建和运行测试代码， 包括JUnit4和UI测试。当你想自动化测试你的应用时， 下面这些库的基于设备的API会非常的有用。 AndroidJUnitRunner. 一个Android的兼容JUnit4的测试运行器 Espresso. 一个适用于应用内部ＵＩ功能验证的ＵＩ测试框架。 UI Automator. 一个适用于跨应用的ＵＩ功能测试的ＵＩ测试框架 Assertion classes因为Android测试支持库的API继承于JUnit, 所以你可以使用assetion方法来展示测试的结果。 一个assertion方法会比较实际的值与预期的值， 并且当结果不符时抛出一个AssertionException异常. 使用assertion可以比loggin的方式更方便， 并且拥有更好的性能。 为了简化测试的开发， 你可以使用 Hamcrest library, 使用Hamcrest matcher APIs可以让你创建更灵活的测试。 Monkey和monkeyrunnerAndroid SDK提供两种功能级app测试的工具。 Monkey Monkey是一个命令行工具， 可以向设备发送模拟的随机事件， 比如按钮， 触屏， 手势等。通过Android Debug Bridge (adb)工具来运行。它可以用来进行压力测试，上报错误，或者多次重复执行一个事件。 monkeyrunner 这是一个用Python实现的工具， 它拥用测试程序API和执行环境。API的功能包括连接到设备， 安装卸载应用， 截屏， 比较图片， 执行一个app的测试包等。使用它的API， 你可以写出一些强大的复杂的测试。使用命令行工具monkeyrunner, 来运行你的程序。 如何构建测试下面的这些文档提供了更详细的信息，教你如何创建和运行各种类型的测试。 构建本地单元测试 构建没有依赖或只有可以模拟的简单依赖的单元测试， 运行于你的本地虚拟机 构建设备单元测试 构建复杂的依赖Android的复杂单元测试， 运行于硬件设备或者模拟器。 自动化界面测试 创建用户界面行为的校验测试， 基于单应用或者跨应用。 测试组件集成 测试用户不能直接交互的组件， 比如Service或者Content Provider 测试显示性能 测试你的应用的界面显示性能， 来保证有平滑的用户体验。 吐槽话说翻这东西真是劳心劳力, 四个小时，闲的么？转载请注明来源 http://www.mapeiyu.com]]></content>
      <categories>
        <category>Android自动化测试</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apk瘦身插件apkeditor新鲜出炉]]></title>
    <url>%2F2017%2F02%2F28%2Fapkeditor%2F</url>
    <content type="text"><![CDATA[ApkEditor是一个Android应用的Gradle插件. 在Android应用中经常会引用一些lib或者aar，但这些第三方的包不可避免会携带一些冗余的资源, 使你的apk变得很大。本插件可以把这些资源从你的apk中剔除出来， 使你的apk变得尽可能得小。 但是， ApkEditor需要你有能力可以分辨这些资源在运行时不会被用到。否则会造成程序的崩溃。 下载和使用 ApkEditor需要检查你的Android应用的运行环境。 所以请保证com.android.application已经被使用。 应用到项目: 123456789buildscript &#123; repositories &#123; jcenter() &#125; dependencies &#123; classpath &apos;com.mapeiyu.apkeditor:apkeditor:1.0.3&apos; &#125;&#125;apply plugin: &apos;apkeditor&apos; 使用apkeditor 插件DSL: 123456789101112apkeditor &#123; exclude &apos;/assets/**/sb/*.so&apos; release &#123; exclude &apos;lib/armeabi/**&apos; &#125; //假定你设置了一个名为black的flavor blackDebug &#123; exclude &apos;/res/layout/**&apos; exclude &apos;res/drawable*/*.xml&apos; &#125; &#125; 然后正常构建或者安装. 生成的apk将会被打包成不含上述规则的资源 解释 在根节点下的exclude， 将会应用到所有的buildType和flavor产生的 apk中. 指定节点下的exclude， 比如release debug backDebug, 只能应用到指定的apk中. exclude可以被多次调用. exclude的设置规则遵循 Java Filesystem API, 并且匹配来源来自于apk的文件结构. (你可解压缩apk, 或者通过Android Studio的分析工具 Build-&gt;Analyze APK...), 如图: 不要理会首个字符 /. 有或者没有都是可以的。 ApkEditor 无法作用到下面的这些文件。（因为这些文件在apk中是必不可少的） /META-INF/** resources.arsc AndroidManifest.xml 与Android Gradle DSL 中的 PackagingOptions 不同 经过测试PackagingOptions无法对这些资源产生影响 /res/ /assets/ .classes 它的设置规则在 flavor和buildType中很不友好。 联系 获得源码 GITHUB. 访问我的个人博客 马培羽 邮件 mason.mpy@gmail.com]]></content>
      <categories>
        <category>原创组件</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Debug 之 命令行调试 （一）]]></title>
    <url>%2F2017%2F02%2F16%2FJava-Debug-%E4%B9%8B-%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%B0%83%E8%AF%95-%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最近在研究编译时注解的一些东东。但是发现调试貌似有点麻烦， 于是找了网上的一些资料也找到了一些处理方法。 但是都是拿来主义， 为什么我们自己不能研究出来解决方法呢？ 本着刨根问底的态度， 决定先研究一下debug的原理。本篇做为系列的第一篇， 从一个小白的角度出发， 一步步把debug研究透彻。要研究一个协议， 先找一个入手点。 平时大家都是用ide来调试， 但是本质一定是有一套协议的， 所以我们先从命令行入手。 准备 首先你要有一个java环境（费话么）。相信对这个主题感性趣的人，这个条件一定是具备的。 准备一个java工程。一个简单的.java文件也可以。这里我提供一个demo。 为了省事拿自己之前写的小工具做例子吧。 希望你能down下来， 后的讲解都是以这个demo为基础的. 路径为 reflect工具 本文基于ubuntu环境。其他环境都不多。 动手 进入命令行， 选一个目录开始我们旅程. 工程拉下来没有？ 没有就执行一下git clone git clone https://github.com/masonTool/reflect 编译工程。 按下面的步骤一步步执行 //进入工程目录 cd reflect //创建类目录, 名字whatever, 用于存放类文件 mkdir aaaa //编译依赖. 我们是要编译sample里面的Main.java, 因为Main.java是java的入口啊。 //说明一下: -g 调试信息选项, 否则不能查看调试过程中的调试信息. 这也是ide的debug模式与release模式的区别 -d 指定类文件编译进我们刚创建的aaaa目录里面 javac -g -d aaaa reflect/src/main/java/com/mason/meizu/reflect/*.java //编译目标类 Main.java 和 prvclass/下的所有的java文件。 //此处选项 -cp 实际是 -classpath. 指定编译上述java文件的依赖类的路径。 刚刚我们编进了aaaa, 此处用一下。 //同时也指定了 -d aaaa , 所以此次编译的结果也放进 aaaa 目录 javac -g -d aaaa -cp aaaa sample/src/com/mason/meizu/sample/prvclass/*.java sample/src/com/mason/meizu/sample/Main.java OK啦， 我们需要调试的资源就具备了。 进入 aaaa目录， tree 一下， 你看到的应该是这样 cd aaaa tree //如果没有命令就 sudo apt-get install tree 装一个 └── com └── mason └── meizu ├── reflect │ ├── RClass.class │ ├── RExecutor.class │ ├── RInstance.class │ ├── RInterface.class │ ├── RInterface$ProxyHandler.class │ └── RParam.class └── sample ├── Main.class ├── Main$Demo.class └── prvclass ├── ClassA.class ├── ClassB.class ├── ClassC.class ├── ClassD4Listener.class └── ClassD4Listener$Listener.class 进入正题 进入调试模式 jdb com.mason.meizu.sample.Main 结果 Initializing jdb ... &gt; 设置断点 输入 stop at com.mason.meizu.sample.Main:30//此处30指定断点在源文件的第30行 结果 Deferring breakpoint com.mason.meizu.sample.Main:30. It will be set after the class is loaded. 运行程程，到断点处停止。 输入 run 结果 run com.mason.meizu.sample.Main Set uncaught java.lang.Throwable Set deferred uncaught java.lang.Throwable &gt; VM Started: Set deferred breakpoint com.mason.meizu.sample.Main:30 Breakpoint hit: &quot;thread=main&quot;, com.mason.meizu.sample.Main.main(), line=30 bci=10 main[1] 看一下当前的变量, 输入 locals 结果 Method arguments: args = instance of java.lang.String[0] (id=408) Local variables: clazzA = instance of com.mason.meizu.reflect.RClass(id=409) main[1] 看一下变量clazzA的详细情况, 输入 dump clazzA 结果 clazzA = { sClassMap: instance of java.util.HashMap(id=410) sConstructorMap: instance of java.util.HashMap(id=411) className: &quot;com.mason.meizu.sample.prvclass.ClassA&quot; classObj: instance of java.lang.Class(reflected class=com.mason.meizu.sample.prvclass.ClassA, id=407) com.mason.meizu.reflect.RExecutor.sMethodMap: instance of java.util.HashMap(id=413) com.mason.meizu.reflect.RExecutor.sFieldMap: instance of java.util.HashMap(id=414) } main[1] 看一下当前运行的线程. 输入 where all 结果 Signal Dispatcher: Finalizer: [1] java.lang.Object.wait (native method) [2] java.lang.ref.ReferenceQueue.remove (ReferenceQueue.java:143) [3] java.lang.ref.ReferenceQueue.remove (ReferenceQueue.java:164) [4] java.lang.ref.Finalizer$FinalizerThread.run (Finalizer.java:209) Reference Handler: [1] java.lang.Object.wait (native method) [2] java.lang.Object.wait (Object.java:502) [3] java.lang.ref.Reference.tryHandlePending (Reference.java:191) [4] java.lang.ref.Reference$ReferenceHandler.run (Reference.java:153) main: [1] com.mason.meizu.sample.Main.main (Main.java:30) main[1] 类似的命令还有如下， 建议你都试一下 next 是执行下一步，相当于Eclipse中的F6 stop in 进入函数实现, 相当于Eclipse中的F5 stop out 运行完当前函数, 相当于Eclipse中的F7 总结本文介绍了一个命令行编译与命令行调试的过程。 这部分工作在日常的开发中都被我们的ide做了。 如果觉得不详细， 看看那个真男人是怎么告诉我们的: man jdb 抽时间我再把他翻译一下， 方便理解。]]></content>
      <categories>
        <category>Java Debug</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吐槽]]></title>
    <url>%2F2017%2F02%2F13%2Ftu-cao%2F</url>
    <content type="text"><![CDATA[人如果不时常问问自己内心，那就会处于一种浑浑噩噩的状态。我就时常这样,偶尔清醒过来嘀咕两句，随后又甘心沉沦进去。然而心中却依然怀揣的自认为是理想的白日梦，以便于沉沦的心安理得。 我想到一个词“惰性”，人都有惰性。拷问自己本身就是一件痛苦的事。忙碌有时也是一种惰性，很多人忙碌并不是勤劳，仅仅是因为习惯了忙碌。习惯是一种让人舒服的状态，也是一种惰性。 生活的状态其实都很随性的，没有一种标准定义什么是好与不好。但财富，在肤浅的层面上却能给人最直观的判断。不要理解的过于深刻，此处财富就是通俗意义上的money。财富好处不言自明。人总共就两种欲望，物质层面与精神层面。财富在这两个方面都能满足。 曾经，甚至我在混沌状态中还在模糊的意识中认为钱不是问题，老子有的是时间。真的以为“赚他一个亿”其实也不是什么笑话。一个亿？也不多嘛。可是细细算个帐下来，哪怕把这个任务均分到30年，每天都需要1万的进帐。貌似有点遥远。 有些人把感恩记在本子上，记录生活中点滴的美好，它的心中充满阳光，甚至照亮了周围。有些却把缺憾记在本子上，记录美好生活中的点滴缺点，时不时拿来回味咀嚼，偿到苦处就破口大骂。或许根源在于自私吧，整天想着自己，整个人就会被黑暗笼罩。心存善念的面对别人，才会让心情阳光明媚。 套几句歌词以自勉，因为我只是在胡扯。 该不该搁下重重的壳 寻找到底哪里有蓝天 随着轻轻的风轻轻地飘 历经的伤都不感觉疼 我要一步一步往上爬 等待阳光静静看着它的脸 小小的天有大大的梦想 重重的壳裹着轻轻地仰望 我要一步一步往上爬 在最高点乘着叶片往前飞 小小的天流过的泪和汗 总有一天我有属于我的天]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[groovy closure]]></title>
    <url>%2F2017%2F02%2F13%2Fgroovy-closure%2F</url>
    <content type="text"><![CDATA[概念闭包是可以用作函数参数和方法参数的代码块. 其实Groovy的闭包更象是一个“代码块”或者方法指针，代码在某处被定义然后在其后的调用处执行 使用示例123456789def square = &#123;it * it&#125; // 定义一个叫square的闭包。it是默认的 参数名称assert 4 == square(2) // 使用闭包assert [1,4,9] == [1,2,3].collect(square) // 使用闭包def closure = &#123; param -&gt; println(&quot;hello $&#123;param&#125;&quot;) &#125;closure.call(&quot;world!&quot;) def closure = &#123; greeting, name -&gt; println(greeting + name) &#125;closure.call(&quot;hello &quot;, &quot;world!&quot;) 闭包用“{}”括起，“-&gt;”前面是参数，后面是处理语句，可以直接调用，也可以使用call调用。不管那种调用，最后groovy编译器都会把编译成对doCall方法的调用，这是groovy对闭包的一个隐藏方法。如果只有一个参数，可以不写，而使用缺省的参数“it”。 如 12def closure = &#123; println(&quot;hello $&#123;it&#125;&quot;) &#125;closure.call(&quot;world!&quot;) 闭包还可当作变量返回 123456def localMethod() &#123; def localVariable = new java.util.Date() return &#123; println localVariable &#125;&#125;def clos = localMethod()clos() Groovy闭包的隐含变量 it：默认的参数名，调用是如果没有传参数，it为null this : 跟Java一样，是定义闭包所在类的一个引用，不管有多少层闭包嵌套，this指向的都是最上层的类。 owner : 封闭闭包的对象(如果只有一层闭包就是this，如果有多层闭包嵌套就是含有此闭包的上层闭包) delegate :缺省值是owner，但是可以改变，后面详说。 123456789101112131415161718192021222324252627282930313233343536373839class Class1 &#123; def closure = &#123; println &quot; ============================== &quot; println &quot;this = &quot;+ this.class.name println &quot;owner = &quot; + owner.class.name println &quot;delegate = &quot; + delegate.class.name def nestedClos = &#123; println &quot; ============================== &quot; println &quot;this = &quot;+ this.class.name println &quot;owner = &quot; + owner.class.name println &quot;delegate = &quot; + delegate.class.name def thirdClos = &#123; println &quot; ============================== &quot; println &quot;this = &quot;+ this.class.name println &quot;owner = &quot; + owner.class.name println &quot;delegate = &quot; + delegate.class.name &#125; thirdClos() &#125; nestedClos() &#125;&#125; def clos = new Class1().closure//clos.delegate = thisclos()执行结果： ============================== this = Class1owner = Class1delegate = Class1 ============================== this = Class1owner = Class1$_closure1delegate = Class1$_closure1 ============================== this = Class1owner = Class1$_closure1_closure2delegate = Class1$_closure1_closure2 闭包实现接口 如果接口只有一个方法 12345678910interface Test&#123; def test()&#125;def test = &#123; println&apos;ok&apos;&#125; as Testtest.test() 多方法接口 1234567891011interface MultiFuncTest&#123; def test1() def test2(str)&#125; def impl = [test1:&#123;println&apos;test&apos;&#125;, test2:&#123;str -&gt; println str&#125;] as MultiFuncTestimpl.test1()impl.test2(&apos;ok&apos;) delegate委托12345678910111213141516class Dog&#123; def play = &#123; &quot;wang wang!&quot; &#125; def childmind = &#123; println delegate.play(); &#125;&#125;class Cat &#123; def play = &#123;&quot;mi mi !&quot;&#125;&#125;def dog = new Dog()def cat = new Cat()dog.childmind()dog.childmind.delegate = cat;dog.childmind()]]></content>
      <categories>
        <category>gradle开发</category>
      </categories>
      <tags>
        <tag>groovy</tag>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反射工具reflect更新到2.2.0版本(有重料)]]></title>
    <url>%2F2017%2F02%2F09%2Freflect-update-2-2-0%2F</url>
    <content type="text"><![CDATA[增加反射interface的实例化支持. 还添加了中文文档说明哦。 点我传送门]]></content>
      <categories>
        <category>原创组件</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>android</tag>
        <tag>reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RX操作符概述]]></title>
    <url>%2F2016%2F11%2F07%2Frx-operation%2F</url>
    <content type="text"><![CDATA[ReactiveX的每种编程语言的实现都实现了一组操作符的集合。不同的实现之间有很多重叠的部分，也有一些操作符只存在特定的实现中。每种实现都倾向于用那种编程语言中他们熟悉的上下文中相似的方法给这些操作符命名。 本文首先会给出ReactiveX的核心操作符列表和对应的文档链接，后面还有一个决策树用于帮助你根据具体的场景选择合适的操作符。最后有一个语言特定实现的按字母排序的操作符列表。 如果你想实现你自己的操作符，可以参考这里：实现自定义操作符 创建操作 用于创建Observable的操作符 Create — 通过调用观察者的方法从头创建一个ObservableDefer — 在观察者订阅之前不创建这个Observable，为每一个观察者创建一个新的ObservableEmpty/Never/Throw — 创建行为受限的特殊ObservableFrom — 将其它的对象或数据结构转换为ObservableInterval — 创建一个定时发射整数序列的ObservableJust — 将对象或者对象集合转换为一个会发射这些对象的ObservableRange — 创建发射指定范围的整数序列的ObservableRepeat — 创建重复发射特定的数据或数据序列的ObservableStart — 创建发射一个函数的返回值的ObservableTimer — 创建在一个指定的延迟之后发射单个数据的Observable变换操作 这些操作符可用于对Observable发射的数据进行变换，详细解释可以看每个操作符的文档 uffer — 缓存，可以简单的理解为缓存，它定期从Observable收集数据到一个集合，然后把这些数据集合打包发射，而不是一次发射一个latMap — 扁平映射，将Observable发射的数据变换为Observables集合，然后将这些Observable发射的数据平坦化的放进一个单独的Observable，可以认为是一个将嵌套的数据结构展开的过程。roupBy — 分组，将原来的Observable分拆为Observable集合，将原始Observable发射的数据按Key分组，每一个Observable发射一组不同的数据ap — 映射，通过对序列的每一项都应用一个函数变换Observable发射的数据，实质是对序列中的每一项执行一个函数，函数的参数就是这个数据项can — 扫描，对Observable发射的每一项数据应用一个函数，然后按顺序依次发射这些值indow — 窗口，定期将来自Observable的数据分拆成一些Observable窗口，然后发射这些窗口，而不是每次发射一项。类似于Buffer，但Buffer发射的是数据，Window发射的是Observable，每一个Observable发射原始Observable的数据的一个子集过滤操作 这些操作符用于从Observable发射的数据中进行选择 Debounce — 只有在空闲了一段时间后才发射数据，通俗的说，就是如果一段时间没有操作，就执行一次操作Distinct — 去重，过滤掉重复数据项ElementAt — 取值，取特定位置的数据项Filter — 过滤，过滤掉没有通过谓词测试的数据项，只发射通过测试的First — 首项，只发射满足条件的第一条数据IgnoreElements — 忽略所有的数据，只保留终止通知(onError或onCompleted)Last — 末项，只发射最后一条数据Sample — 取样，定期发射最新的数据，等于是数据抽样，有的实现里叫ThrottleFirstSkip — 跳过前面的若干项数据SkipLast — 跳过后面的若干项数据Take — 只保留前面的若干项数据TakeLast — 只保留后面的若干项数据组合操作 组合操作符用于将多个Observable组合成一个单一的Observable And/Then/When — 通过模式(And条件)和计划(Then次序)组合两个或多个Observable发射的数据集CombineLatest — 当两个Observables中的任何一个发射了一个数据时，通过一个指定的函数组合每个Observable发射的最新数据（一共两个数据），然- 后发射这个函数的结果Join — 无论何时，如果一个Observable发射了一个数据项，只要在另一个Observable发射的数据项定义的时间窗口内，就将两个Observable发射的数据合并发射Merge — 将两个Observable发射的数据组合并成一个StartWith — 在发射原来的Observable的数据序列之前，先发射一个指定的数据序列或数据项Switch — 将一个发射Observable序列的Observable转换为这样一个Observable：它逐个发射那些Observable最近发射的数据Zip — 打包，使用一个指定的函数将多个Observable发射的数据组合在一起，然后将这个函数的结果作为单项数据发射错误处理 这些操作符用于从错误通知中恢复 Catch — 捕获，继续序列操作，将错误替换为正常的数据，从onError通知中恢复Retry — 重试，如果Observable发射了一个错误通知，重新订阅它，期待它正常终止辅助操作 一组用于处理Observable的操作符 Delay — 延迟一段时间发射结果数据Do — 注册一个动作占用一些Observable的生命周期事件，相当于Mock某个操作Materialize/Dematerialize — 将发射的数据和通知都当做数据发射，或者反过来ObserveOn — 指定观察者观察Observable的调度程序（工作线程）Serialize — 强制Observable按次序发射数据并且功能是有效的Subscribe — 收到Observable发射的数据和通知后执行的操作SubscribeOn — 指定Observable应该在哪个调度程序上执行TimeInterval — 将一个Observable转换为发射两个数据之间所耗费时间的ObservableTimeout — 添加超时机制，如果过了指定的一段时间没有发射数据，就发射一个错误通知Timestamp — 给Observable发射的每个数据项添加一个时间戳Using — 创建一个只在Observable的生命周期内存在的一次性资源条件和布尔操作 这些操作符可用于单个或多个数据项，也可用于Observable All — 判断Observable发射的所有的数据项是否都满足某个条件Amb — 给定多个Observable，只让第一个发射数据的Observable发射全部数据Contains — 判断Observable是否会发射一个指定的数据项DefaultIfEmpty — 发射来自原始Observable的数据，如果原始Observable没有发射数据，就发射一个默认数据SequenceEqual — 判断两个Observable是否按相同的数据序列SkipUntil — 丢弃原始Observable发射的数据，直到第二个Observable发射了一个数据，然后发射原始Observable的剩余数据SkipWhile — 丢弃原始Observable发射的数据，直到一个特定的条件为假，然后发射原始Observable剩余的数据TakeUntil — 发射来自原始Observable的数据，直到第二个Observable发射了一个数据或一个通知TakeWhile — 发射原始Observable的数据，直到一个特定的条件为真，然后跳过剩余的数据算术和聚合操作 这些操作符可用于整个数据序列 Average — 计算Observable发射的数据序列的平均值，然后发射这个结果Concat — 不交错的连接多个Observable的数据Count — 计算Observable发射的数据个数，然后发射这个结果Max — 计算并发射数据序列的最大值Min — 计算并发射数据序列的最小值Reduce — 按顺序对数据序列的每一个应用某个函数，然后返回这个值Sum — 计算并发射数据序列的和连接操作 一些有精确可控的订阅行为的特殊Observable Connect — 指示一个可连接的Observable开始发射数据给订阅者Publish — 将一个普通的Observable转换为可连接的RefCount — 使一个可连接的Observable表现得像一个普通的ObservableReplay — 确保所有的观察者收到同样的数据序列，即使他们在Observable开始发射数据之后才订阅转换操作 To — 将Observable转换为其它的对象或数据结构Blocking 阻塞Observable的操作符操作符决策树 几种主要的需求 直接创建一个Observable（创建操作）组合多个Observable（组合操作）对Observable发射的数据执行变换操作（变换操作）从Observable发射的数据中取特定的值（过滤操作）转发Observable的部分值（条件/布尔/过滤操作）对Observable发射的数据序列求值（算术/聚合操作）]]></content>
      <categories>
        <category>RX</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>RX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不做工作狂]]></title>
    <url>%2F2016%2F10%2F15%2FWorkaholism%2F</url>
    <content type="text"><![CDATA[我们的文化颂扬工作狂思想。我们听说人们会午夜鏖战。他们开夜车而在办公室睡觉。 这被认为是一种把全身投入一个项目的标志。工作的总量不等于过量的工作。这样的工作狂不仅没必要,而且很傻。做得多并不意味着你足够用心或者完成得更多。仅仅意味着你做得多。 工作狂最后制造的麻烦比解决的麻烦多。首先,工作狂好似没有合理利用时间。当筋疲力尽时,会制造更多麻烦。工作狂也抓不住要点。他们想用砸大把大把的时间来解决事情。他们想用蛮干来弥补一些小技巧。结果就是粗野的解决。 他们甚至会制造危机。他们不会去找高效的方法因为他们确实喜欢加班。他们享受英雄般的感觉。他们制造出问题(通常是无意识地)以便多多工作。工作狂若是不留到很晚会觉得仅仅花合理的时间工作是不合理的。这会四处充满内疚感和低士气。并且,产生理所当然的想法──留守很晚是职责之外的事,就算他们不是真的富有成效。如果你所做的都是工作,你不太可能得到很好的评价。你的价值和决定会以误解告终。你不能判断额外的努力是值得还是不值得。你只会彻底累垮。没有人能疲倦中做出明晰的决定。 最后,工作狂并不比非工作狂达成更多目标。他们也许会宣称自己是完美主义者,但那只是意味着浪费时间在注意一些不重要的细节而不是着手于下一个任务。 工作狂不是英雄。他们不是在节约时间而是在浪费。真正的英雄已经回到家中,因为她找到更快的方法把工作做好。]]></content>
      <categories>
        <category>书摘</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[blog的hexo配置移植方法]]></title>
    <url>%2F2016%2F10%2F09%2Fhexo-blog-config%2F</url>
    <content type="text"><![CDATA[介绍如何将个人博客的hexo后台移植到另外的设备上, 使可以多平台上可以同步操作博客后台. 0. 进入到你的hexo目录, 执行git init 生成git仓库, 将git仓库上传到github.//初始化仓库 cd hexo git init //提交init git add .gitignore git add .npmignore git add _config.yml git add source/ git add themes/ git commit -a -m init //上传github服务器, 首先你要在github上添加了新的远程仓库 git remote add github git@gitlab.meizu.com:xxxx/xxxx.git push -u github master 将配置文件上传至github, 看我的配置文件为GITHUB 1. 进入移植设备. 将本工程下拉, 会生成目录blog_configmkdir temp git clone git@github.com:masonTool/blog_config.git 2. 再拷贝一份blog_config(命名为blog_config1), 进入目录cp -r blog_config/ blog_config1 cd blog_config1 3. 依次执行指令npm install hexo --save hexo init npm install hexo-deployer-git --save 4. 执行完上一步, 会生成文件夹node_modules, 文件夹中应该有如下的文件hexo hexo-deployer-git dhexo-generator-archive hexo-generator-category hexo-generator-index hexo-generator-tag hexo-renderer-ejs hexo-renderer-marked hexo-renderer-stylus hexo-server 5. 移动node_modules到原blog_config文件中. 再删除blog_config1完成了移植. 此时你可以在多设备上写文章. 通过git来管理配置了.]]></content>
      <categories>
        <category>博客开发</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Reflect Tool]]></title>
    <url>%2F2016%2F10%2F08%2Fjava-reflect-tool%2F</url>
    <content type="text"><![CDATA[Background Java reflect operation always confuse me, cause is not so intuitive. And it’s low efficiency lead us can not use it very frequently. This reflect tool can help you simplify the operation and cache the reflect results. Hope can help you. Library projectsSee the project in GITHUB Download the latest JAR or grab via Maven: For gradle: compile &apos;com.github.masontool:reflect:2.1.0&apos; For maven: &lt;dependency&gt; &lt;groupId&gt;com.github.masontool&lt;/groupId&gt; &lt;artifactId&gt;reflect&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; UsefulI can show you the sample , it’s simple; ClassA: package com.mason.meizu.sample.prvclass; class ClassA { protected static String staticString = &quot;HELLO&quot;; private String normalString = &quot;WORLD&quot;; private static Integer plus(Integer a, Integer b) { return a+b; } private long minus(long a, long b) { return a - b; } private static int plus(ClassB b, ClassC c) { return b.value + c.value; } } ClassB: package com.mason.meizu.sample.prvclass; class ClassB { int value = 5; } ClassC: package com.mason.meizu.sample.prvclass; class ClassC { int value = 4; } We suppose all the classes, parameters, methods should be reflected. You can do like this: Get / Set static value in class. RClass clazzA = new RClass(&quot;com.mason.meizu.sample.prvclass.ClassA&quot;); clazzA.setValue(&quot;staticString&quot;, &quot;static changed!!!!!&quot;); String staticString = clazzA.getValue(&quot;staticString&quot;); Get / Set normal value in class. RInstance instanceA = clazzA.newWrappedInstance(); instanceA.setValue(&quot;normalString&quot;, &quot;normal changed!!!!!&quot;); String normalString = instanceA.getValue(&quot;normalString&quot;); Excute static method. Integer plusResult = clazzA.execute(&quot;plus&quot;, Integer.class, 5, Integer.class, 4); Excute normal method. long minusResult = instanceA.execute(&quot;minus&quot;, long.class, 5, long.class, 4); Support nested call. Here is a complex sample RClass clazzB = new RClass(&quot;com.mason.meizu.sample.prvclass.ClassB&quot;); RClass clazzC = new RClass(&quot;com.mason.meizu.sample.prvclass.ClassC&quot;); int complexResult1 = clazzA.execute(&quot;plus&quot;, clazzB, clazzB.newInstance(), clazzC, clazzC.newInstance()); Feedback Any question you can contact me with email 307416073@qq.com.]]></content>
      <categories>
        <category>原创组件</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>android</tag>
        <tag>reflect</tag>
      </tags>
  </entry>
</search>
